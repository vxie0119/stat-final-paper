---
title: "Decoding the Impact: Statistical Analysis of Factors Contributing to NFL Injuries"
author: "Vincent Xie"
bibliography: bibliography.bib
toc: false
number-sections: false
execute:
    echo: false
highlight-style: pygments
format: 
  html: 
    code-fold: true
    html-math-method: katex
  pdf: 
    fontsize: 12pt
    geometry: 
      - top=30mm
      - left=20mm
header-includes:
  - \usepackage{setspace}
  - \doublespacing
##  docx: default
---
```{python}
# Packages
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from scipy.stats import chi2_contingency
import numpy as np
import warnings

from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

warnings.filterwarnings('ignore', category=FutureWarning)
```

# Abstract

This paper investigates the diverse factors that significantly influence the occurrence and characteristics of injuries within the National Football League (NFL). Using a dataset that encompasses injury records, player activities, and environmental conditions, this research explores the interplay between player positions, play types, game conditions (including weather and surface type), and their relationship to injury occurrences. Employing statistical techniques such as logistic regression, Chi-square tests, and ANOVA, the study seeks to identify significant correlations and causative factors that can inform injury prevention strategies. The goal is to enhance understanding of injury dynamics in professional football and contribute to improved player safety measures. Insights gained may challenge existing assumptions and lead to innovative health strategies in sports management, significantly impacting player care and game integrity.

# Introduction

In the realm of professional sports, particularly within the National Football League (NFL), injuries are an inevitable consequence of high-impact and physically demanding activities. The incidence and severity of these injuries not only affect player health and career longevity but also influence team dynamics and league operations. This study focuses on a comprehensive analysis of various factors that might contribute to the occurrence and nature of injuries, specifically lower body extremities, in the NFL, aiming to identify patterns and potential preventative measures. By identify the preventative measures, athletes can worry less about how injuries during their career will affect their life after. The importance of this research lies not only in enhancing player safety but also in advancing the broader understanding of injury prevention in contact sports.

Prior research in sports medicine and athletic injuries has primarily focused on immediate causes and rehabilitation of injuries. Within the NFL, the annual health and safety reports provide aggregate data on injury types and frequencies, which serve as a baseline for this study. However, there is a lack of comprehensive analysis that integrates environmental conditions, play strategies, and player-specific variables to predict and analyze injury occurrences comprehensively. There is also research on how the surface type affects the frequency in lower extremity injuries. The results show a positive correlation between the two factors. This paper will also perform statistical analysis on how specific factors affect the frequency of lower extremity injuries. It may support the claims of prior research or provide new insight on other causes that may contribute to these injuries.

While existing studies have laid a solid foundation in understanding the factors influencing sports injuries, gaps remain in the holistic analysis of how combined factors like weather conditions, playing surface type, player position, and specific play scenarios contribute to the risk and nature of injuries. Most studies have not fully utilized the granular data now available through player tracking technologies and detailed game logs, which can offer deeper insights into the conditions under which injuries most frequently occur.

This paper contributes to the existing literature by employing statistical techniques to analyze a unique dataset combining player injury records, play-by-play data, and environmental conditions. By doing so, it aims to:

+ Quantify the impact of various factors on the likelihood and severity of injuries.
+ Identify specific conditions or scenarios that significantly increase injury risk.
+ Offer recommendations for injury prevention based on empirical evidence.

The remainder of this paper is structured as follows:

1. Data Description and Cleaning: This section details the datasets used, sources, variables of interest, and the nature of the data. If there are irrelevant variables or emptiness, it will be removed or filled in.
2. Research Design and Methods: Here, the statistical methods applied in the analysis, such as logistic regression and ANOVA, are discussed along with the rationale behind their use.
3. Results: This section presents the findings of the study, discussing how various factors correlate with injury occurrences and their implications.
4. Discussion: Insights and interpretations of the results are discussed, along with their implications for injury prevention strategies in the NFL.
5. Conclusion: The paper concludes with a summary of the findings and their contributions to sports injury research and practice, along with suggestions for future research.

# Data

The data utilized in this study comes from a [Kaggle](https://www.kaggle.com/competitions/nfl-playing-surface-analytics/data) data set sponsored by the National Football League (NFL). The files include injurys records and a list of information that detail the conditions of the play and information about the location and weather. There is another data set that displays detailed player movement metrics but the file is simply too large. For the purpose of this paper, we will utilize the first two datasets. The dataset covers two NFL seasons from recent years, although specific years are not detailed. This period is crucial for understanding current injury trends and preventive measures.

This data is integral to analyzing the occurrence and nature of injuries in the NFL because it includes variables directly related to the research questions, such as player positions, field types, weather conditions, and specific injury details. These variables allow for a nuanced analysis of how different conditions correlate with injury risks. 

Preliminary exploratory analysis would involve:

+ Descriptive statistics to summarize the data, such as average injury durations, frequency of injuries by body part, and common player positions associated with injuries.
+ Visualization techniques, including heatmaps of injuries by field type and line graphs of injury occurrences over time.
+ Correlation matrices to identify potential relationships between variables such as weather conditions and injury rates.

This structured approach will guide readers through the foundational data used in the study, establishing the groundwork for more detailed statistical analysis and interpretation in subsequent sections of your paper.

Data cleaning is a necessary step to examine whether or not there is incomplete data. 

```{python}
# Load the datasets
injury = pd.read_csv('data/InjuryRecord.csv')
plays = pd.read_csv('data/PlayList.csv')
new_injury = pd.read_csv('data/mod_InjuryRecord.csv')
new_plays = pd.read_csv('data/mod_PlayList.csv')
```

```{python}
# Summarize missing data for InjuryRecord.csv
injury_missing_summary = injury.isnull().sum()
injury_missing_summary = injury_missing_summary[injury_missing_summary > 0].rename('InjuryRecord')

# Summarize missing data for PlayList.csv
playlist_missing_summary = plays.isnull().sum()
playlist_missing_summary = playlist_missing_summary[playlist_missing_summary > 0].rename('PlayList')

# Calculate the ratio of missing data to total entries for each dataset
missing_data_ratio_injury = (injury_missing_summary.sum() / len(injury)) * 100
missing_data_ratio_playlist = (playlist_missing_summary.sum() / len(plays)) * 100

# Create a DataFrame from the missing data summaries
missing_data_summary = pd.DataFrame({
    'InjuryRecord.csv': injury_missing_summary,
    'PlayList.csv': playlist_missing_summary
})

# Fill NaN values with zero and convert all numeric counts to integers
missing_data_summary = missing_data_summary.fillna(0).astype(int)

# Convert all numeric counts to integers (ensures whole numbers)
missing_data_summary = missing_data_summary.astype(int)

# Add the ratio of missing data as a new row
missing_data_summary.loc['Missing Data Ratio (%)'] = [f"{missing_data_ratio_injury:.2f}%", f"{missing_data_ratio_playlist:.2f}%"]

# Transpose the DataFrame for better readability
missing_data_summary = missing_data_summary.T

# Rename index to indicate it's the file name and adjust column names if needed
missing_data_summary.index.name = 'File Name'

# Display the DataFrame neatly
print(missing_data_summary)
```

From `InjuryRecord.csv`, there are only 28 values missing in the `PlayKey` column from the original 105. At 27%, there is a significant amount of missing data entries. However, it would be difficult to fill in the missing entries without using an external dataset. This variable is also within the `PlayList.csv` file so it can be used to fill in the data in `InjuryRecord.csv` (if applicable). In `PlayList.csv`, 13% of the data is missing, mainly in `StadiumType`, `Weather`, and `PlayType`. Similar to before, it is difficult to fill in data without an external resource. For now, the models and analysis will use the data available in the files.

```{python}
# Fill missing 'PlayKey' values with 'GameID' concatenated with '-1'
injury['PlayKey'] = injury.apply(
    lambda row: f"{row['GameID']}-1" if pd.isnull(row['PlayKey']) else row['PlayKey'],
    axis=1
)

# Save the modified dataframe if needed
injury.to_csv('data/mod_InjuryRecord.csv', index=False)
```

For the missing entries in `InjuryRecord.csv`, we can fill in the missing data by formatting the missing values based on the `GameID`. This step allows us to locate the data between each file and determine important factors that contribute to injuries.

```{python}
# Bar chart for frequency of stadium types in PlayList
stadium_freq = plays['StadiumType'].value_counts()
plt.figure(figsize=(5, 2))
stadium_freq.plot(kind='bar', color='lightgreen')
plt.title('Frequency of Stadium Types')
plt.xlabel('Stadium Type')
plt.ylabel('Frequency')
plt.show()
```

This graph models all of the different stadium types that are in the file. Notice how there are many repeats that can be combined. In order to reduce repetitiveness, these values can be cleaned by combining like-values.

```{python}
# A quick view at the 'StadiumType' unique values to understand the variations
stadium_types = plays['StadiumType'].unique()

stadium_type_mapping = {
    'Retr. Roof-Closed': 'Retr. Roof - Closed',
    'Retr. Roof-Open': 'Retr. Roof - Open',
    'Outdoor': 'Outdoors',
    'Ourdoor': 'Outdoors',
    'Oudoor': 'Outdoors',
    'Outddors': 'Outdoors',
    'Outdor': 'Outdoors',
    'Outside': 'Outdoors',
    'Heinz Field': 'Outdoors',  # Assuming Heinz Field is always outdoor
    'Cloudy': 'Outdoors',  # Assuming 'Cloudy' is an outdoor condition and not a stadium type
    'Indoor': 'Indoors',
    'Domed': 'Dome',
    'Domed, closed': 'Dome, closed',
    'Domed, Open': 'Dome, closed',
    'Closed Dome': 'Dome, closed',
    'Retr. Roof Closed': 'Retr. Roof - Closed'
    # More mappings can be added here based on the actual data
}

# Standardize the 'StadiumType' column
plays['StadiumType'] = plays['StadiumType'].replace(stadium_type_mapping)

# Save the modified dataframe if needed
plays.to_csv('data/mod_PlayList.csv', index=False)

# Calculate the new frequency of each stadium type
cleaned_stadium_freq = plays['StadiumType'].value_counts()

# Bar chart for frequency of stadium types in PlayList
stadium_freq = plays['StadiumType'].value_counts()
plt.figure(figsize=(6, 1))
stadium_freq.plot(kind='bar', color='lightgreen')
plt.title('Frequency of Stadium Types')
plt.xlabel('Stadium Type')
plt.ylabel('Frequency')
plt.show()
```

We can also group the temperatures and weather so make the data set more clean. Otherwise, there will be too many unique values. The labels for temperature are the following:

+ Cold: Below 50F
+ Cool: 50F-60F
+ Mild: 61F-70F
+ Warm: 71F-80F
+ Hot: Above 80F

For weather, it has been grouped to `rain`, `overcast`, `clear`, `snow`, and any others were grouped to `None` or `Unknown`.

```{python}
# Define the temperature bins and labels
bins = [-float('inf'), 50, 60, 70, 80, float('inf')]
labels = ['Cold', 'Cool', 'Mild', 'Warm', 'Hot']

# Replace the temperature values with categorical labels directly
plays['Temperature'] = pd.cut(plays['Temperature'], bins=bins, labels=labels)

# Save the modified dataframe if needed
plays.to_csv('data/mod_PlayList.csv', index=False)
```

```{python}
def map_weather(weather):
    if pd.isna(weather):
        return 'Unknown'
    weather = weather.lower()
    # Broadening the conditions for rain to capture "rainy", "showers", etc.
    if any(word in weather for word in ['rain', 'showers', 'rainy', 'rain shower']):
        return 'Rain'
    # Check for overcast and cloudy conditions
    elif any(word in weather for word in ['overcast', 'cloudy']):
        return 'Overcast'
    # Broadening conditions for clear to include "clear", "sunny", etc.
    elif any(word in weather for word in ['clear', 'sunny', 'sun']):
        return 'Clear'
    # Check for snow
    elif 'snow' in weather:
        return 'Snow'
    # Indoor conditions
    elif any(word in weather for word in ['indoor', 'indoors', 'controlled climate', 'n/a', 'none']):
        return 'None'
    return 'Unknown'

# Apply the mapping function to the Weather column
plays['Weather'] = plays['Weather'].apply(map_weather)

# Save the modified dataframe if needed
plays.to_csv('data/mod_PlayList.csv', index=False)
```

# Modeling

From the collected the data, it is important to visualize the occurrences of injuries, especially the type and by the position. Below is a heat map that shows how many injury occurrences there are based on position. In terms of the most frequent injuries, there are many `Ankle` and `Knee` injuries, specifically in the `Linebacker` and `Wide Receiver` position groups. `Toes` tend to be the least frequent, with this data set only having one instance. This heatmap shows that with the playstyle of the sport, injured players tend to have knee and ankle issues. 

```{python}
# Merge injury_record and playlist on PlayerKey
merged_data = pd.merge(new_injury, plays, on='PlayKey', how='inner')

# Group by 'RosterPosition' and 'BodyPart' and count the occurrences
injury_by_position = merged_data.groupby(['RosterPosition', 'BodyPart']).size().reset_index(name='Frequency')

# Create a pivot table with 'RosterPosition' as index, 'BodyPart' as columns, and 'Frequency' as values
pivot_table = injury_by_position.pivot_table(index='RosterPosition', columns='BodyPart', values='Frequency', fill_value=0)

# Convert frequencies to integers
pivot_table = pivot_table.astype(int)

# Plot a heatmap to visualize the frequency of each type of injury by each position group
plt.figure(figsize=(5, 2))
sns.heatmap(pivot_table, annot=True, cmap="viridis")
plt.title('Frequency of Each Type of Injury by Position Group')
plt.xlabel('Body Part')
plt.ylabel('Roster Position')
plt.show()
```

```{python}
# Given the code snippets provided by the user, we will combine both plots into a single figure with subplots.

# First, let's recreate the datasets based on the previous analysis steps.
# NOTE: For the purposes of this demonstration, we will assume 'new_injury' and 'new_plays' are the injury_data and playlist_data respectively.

injury_counts = new_injury['Surface'].value_counts()
injury_percentages = (injury_counts / injury_counts.sum() * 100).round(2)

# Calculate the predominant surface for each game in the playlist data
predominant_surface_per_game = new_plays.groupby('GameID')['FieldType'].agg(pd.Series.mode).to_frame()
surface_type_counts = predominant_surface_per_game['FieldType'].apply(lambda x: x[0] if isinstance(x, list) else x).value_counts()
surface_type_percentages = (surface_type_counts / surface_type_counts.sum() * 100).round(2)

# Set up a figure with two subplots
fig, axs = plt.subplots(1, 2, figsize=(12, 6))  # Increased figure size for clarity

# Plot for injuries by surface type
axs[0].bar(injury_counts.index, injury_counts, color='skyblue')
axs[0].set_title('Number of Injuries by Surface Type')
axs[0].set_xlabel('Surface Type')
axs[0].set_ylabel('Number of Injuries')
axs[0].grid(axis='y', linestyle='--', alpha=0.7)

# Annotate percentages above the bars for the first plot
for i, v in enumerate(injury_counts):
    axs[0].text(i, v + 1, f'{injury_percentages.iloc[i]}%', ha='center', va='bottom')

# Plot for number of games played on each surface type
axs[1].bar(surface_type_counts.index, surface_type_counts, color=['green', 'blue'])
axs[1].set_title('Number of Games Predominantly Played on Each Surface Type')
axs[1].set_xlabel('Surface Type')
axs[1].set_ylabel('Number of Games')
axs[1].grid(axis='y', linestyle='--', alpha=0.7)

# Annotate percentages above the bars for the second plot
for i, v in enumerate(surface_type_counts):
    axs[1].text(i, v + 20, f'{surface_type_percentages.iloc[i]}%', ha='center', va='bottom')

# Set tight layout to prevent overlap
plt.tight_layout()

# Show the combined plot
plt.show()
```


The comparison of injury occurrence and the type of playing surface presents a significant finding in the data. There's a higher rate of injuries reported on synthetic surfaces at 54.29%, despite more games being played on natural grass, which hosts 57.97% of games. This discrepancy suggests that synthetic surfaces may carry a higher risk of injury compared to natural grass. This data can inform decisions about player safety and surface selection, potentially leading to considerations for the use of natural grass to reduce injury rates.

Given this data, it appears that the type of playing surface may be a significant contributing factor to injury risks in sports, particularly affecting players in positions that require dynamic movements such as sudden turns and sprints. These insights can inform decisions regarding player training, game scheduling, and perhaps the selection or maintenance of playing surfaces to mitigate injury risks. Further research may be warranted to explore the causative factors behind these observations and to develop strategies for injury prevention.

```{python}
# To reflect the correct recovery time, we need to adjust the data.
# If there's a '1' in every 'DM' column for a record, the recovery is 42 days.
# If there are '1's in the first three 'DM' columns, recovery is 28 days, and so on.

# Create a new column that determines the maximum recovery time based on the 'DM' columns
def determine_recovery(row):
    if row['DM_M42'] == 1:
        return '42 Days'
    if row['DM_M28'] == 1:
        return '28 Days'
    if row['DM_M7'] == 1:
        return '7 Days'
    if row['DM_M1'] == 1:
        return '1 Day'
    return 'Unknown'

new_injury['RecoveryTime'] = new_injury.apply(determine_recovery, axis=1)

# Group by BodyPart and RecoveryTime to count the number of injuries
recovery_counts = new_injury.groupby(['BodyPart', 'RecoveryTime']).size().unstack(fill_value=0)

# Reorder the columns to match the desired recovery time order
recovery_counts = recovery_counts[['1 Day', '7 Days', '28 Days', '42 Days']]

# Calculate the percentage of recovery counts for each body part
recovery_percent = recovery_counts.div(recovery_counts.sum(axis=1), axis=0)

# Create the stacked bar chart with pastel colors
pastel_colors = ['#77dd77', '#fdfd96', '#84b6f4', '#ffbdbd']  # Pastel colors for green, yellow, blue, and pink respectively

# Plot the stacked bar chart with ordered recovery times
ax = recovery_percent.plot(kind='bar', stacked=True, figsize=(10, 6), color=pastel_colors)

# Annotate the counts on the bars with contrast adjustment for readability
for n, x in enumerate([*recovery_counts.index.values]):
    for (proportion, count, y_loc) in zip(recovery_percent.loc[x],
                                          recovery_counts.loc[x],
                                          recovery_percent.loc[x].cumsum()):
        # To ensure the text is readable, choose a text color with good contrast
        text_color = 'black'  # Black for contrast on pastel colors
        if count > 0:  # Only annotate non-zero counts
            ax.text(x=n, y=y_loc - proportion/2, s=int(count), ha='center', va='center', color=text_color)

ax.figure.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x*100)}%'))

plt.title('Proportion of Injury Types by Recovery Time')
plt.xlabel('Body Part Injured')
plt.ylabel('Proportion of Total Injuries')
plt.legend(title='Recovery Time', bbox_to_anchor=(1.04,1), loc="upper left")
plt.tight_layout()
plt.show()
```

The provided stacked bar chart illustrates the proportion of injuries categorized by body part and further subdivided by recovery time. The body parts considered are the ankle, foot, heel, knee, and toes. The recovery time is categorized into four distinct time frames: 1 day, 7 days, 28 days, and 42 days.

Observations from the chart include:

+ Knee injuries comprise a significant portion of the injuries, with a notable number requiring a recovery time of 28 days, indicating potential severity.
+ Ankle injuries are the second most common and show a varied recovery time, with the majority needing either 1 or 28 days to recover.
+ Foot and heel injuries are less frequent, but foot injuries display a substantial number requiring the longest recovery time of 42 days.
+ Toe injuries are the least common; however, they show a split between short recovery (1 day) and extended recovery (28 days).

The data suggests that knee and ankle injuries are not only frequent but also often require prolonged periods of recovery. The severity indicated by longer recovery times emphasizes the need for targeted preventive measures for these particular body parts. The substantial number of injuries requiring the longest recovery period for both the knee and foot indicates that these injuries may be particularly severe or complex. The analysis of this data can be crucial for healthcare providers, coaches, and sports organizations in understanding injury patterns and implementing strategies for injury prevention and rehabilitation.

# Methods

**Injury Occurrence based on Surface Type**

```{python}
# Create a set of unique keys from InjuryRecord which indicates injuries
injury_keys = set(new_injury['PlayKey'])

# Create a binary variable in PlayList that indicates whether an injury occurred
plays['InjuryOccurred'] = plays['PlayKey'].isin(injury_keys).astype(int)

# Ensure 'Surface' column is in the PlayList dataset and check data
if 'FieldType' not in plays.columns:
    print("Error: 'FieldType' column is missing from PlayList dataset.")
else:
    # Create a contingency table of injuries by surface type
    contingency_table = pd.crosstab(plays['InjuryOccurred'], plays['FieldType'])

    # Perform the Chi-Square test
    chi2, p, dof, expected = chi2_contingency(contingency_table)

    print(f"Chi-Square Statistic: {chi2:.3f}, p-value: {p:.3f}")
```

The methods section details a statistical approach to establish a correlation between the type of playing surface and the occurrence of injuries. A binary variable is created within the plays dataset to indicate the occurrence of an injury, with each play cross-referenced against a set of unique injury identifiers from the new_injury dataset.

Following this, a contingency table is constructed to tabulate the frequency of injuries against each type of playing surface, as recorded in the plays dataset. A Chi-Square test of independence is then applied to this contingency table to evaluate if there is a statistically significant association between playing surface type and injury occurrence.

The Chi-Square statistic and corresponding p-value are critical in this analysis. If the p-value is found to be less than a commonly accepted threshold (e.g., 0.05), the null hypothesis — which assumes no relationship between surface type and injury occurrence — is rejected. This suggests that the surface type may indeed play a role in injury risk, an insight that could be instrumental in shaping preventative measures in sports environments.

**Weather conditions across different injury types**

```{python}
# Prepare the data for chi-square test on weather and injury types
# Drop rows where 'Weather' or 'BodyPart' is NaN since they can't be used in the test
weather_injury_data = merged_data.dropna(subset=['Weather', 'BodyPart'])

# Create the contingency table for 'Weather' and 'BodyPart'
contingency_weather_injury = pd.crosstab(weather_injury_data['Weather'], weather_injury_data['BodyPart'])

# Perform the chi-square test
chi2_weather_injury, p_value_weather_injury, dof_weather_injury, expected_weather_injury = chi2_contingency(contingency_weather_injury)

# Display the chi-square test results and the contingency table (if small enough)
contingency_weather_injury.shape, (chi2_weather_injury, p_value_weather_injury)
```

The Chi-Square test conducted on the contingency table of weather conditions and body parts injured returned a non-significant result, indicating no strong evidence of an association between the two variables within the dataset analyzed. The shape of the contingency table and the values of the Chi-Square statistic and p-value suggest that variations in weather do not statistically affect the likelihood of different types of injuries occurring. This analysis supports the conclusion that, at least in this data set, weather conditions do not appear to be a significant factor in the occurrence of injuries to specific body parts.

**Temperature vs. injury occurrence**

```{python}
# Merging the datasets on 'PlayerKey', 'GameID', and 'PlayKey'
merged_data = pd.merge(new_plays, new_injury, how='left', on=['PlayerKey', 'GameID', 'PlayKey'])

# Adding a binary column for whether an injury occurred
merged_data['InjuryOccurred'] = merged_data['BodyPart'].notna()

# Convert temperature categories into numerical codes for logistic regression
temperature_mapping = {'Cold': 0, 'Cool': 1, 'Mild': 2, 'Warm': 3, 'Hot': 4}
merged_data['TemperatureCode'] = merged_data['Temperature'].map(temperature_mapping)

# Prepare data for logistic regression
# Dropping rows where 'TemperatureCode' is NaN
temperature_injury_data = merged_data.dropna(subset=['TemperatureCode'])

# Logistic Regression: InjuryOccurred ~ Temperature
X_temp = temperature_injury_data[['TemperatureCode']]  # Independent variable
X_temp = sm.add_constant(X_temp)  # Adding a constant for the intercept term
y_temp = temperature_injury_data['InjuryOccurred']  # Dependent binary variable

# Fit the logistic regression model
logit_model_temp = sm.Logit(y_temp, X_temp)
result_temp = logit_model_temp.fit()

# Display the summary of the logistic regression
result_temp.summary()
```

The logistic regression analysis presented in the summary focuses on the relationship between temperature and injury occurrence. The model, which predicts the likelihood of an injury based on temperature, uses a temperature code that categorizes weather conditions from cold to hot. The results show that for every unit increase in the temperature code, the log-odds of injury occurrence increases by 0.1384, which is statistically significant with a p-value of 0.038. This suggests that as the temperature category increases from colder to warmer, the probability of injury occurrence slightly increases.

The model's overall fit, indicated by the pseudo R-squared, is very low, which suggests that the temperature alone does not provide a strong predictive power for the occurrence of injuries. However, the statistical significance of the temperature variable indicates that there is a relationship worthy of further investigation.

It's important to note that the model controls for temperature but not for other potentially confounding variables. Thus, while temperature has been found to have a significant association with injury occurrence, the exact nature of this relationship and its practical implications would require a more in-depth analysis that includes a broader set of variables.

# Conclusion

The multifaceted analysis presented in this paper provides valuable insights into the factors contributing to injury occurrences within the NFL. Through the use of logistic regression, Chi-square tests, and other statistical methods, the research examined the influence of playing surfaces, weather conditions, and temperature on the likelihood of player injuries.

Key findings indicate that synthetic playing surfaces may have a higher association with injury occurrence compared to natural grass. This data underscores the need for sports leagues to consider playing surface characteristics in their injury prevention strategies. Additionally, while weather conditions did not show a significant association with the types of injuries sustained, temperature did exhibit a measurable impact, suggesting that warmer conditions could potentially increase the probability of injury.

Despite the robustness of the statistical analysis, the conclusions of this study are subject to the limitations of the dataset and the scope of the research methods employed. The predictive power of the models for injury occurrence was relatively low, highlighting the complexity of injury dynamics and the potential influence of unaccounted variables such as player fitness, equipment, and play context.

This research contributes to the body of knowledge in sports medicine and injury prevention by highlighting the importance of environmental and situational factors in the occurrence of NFL injuries. The findings provide a foundation for further research to explore additional variables and employ more sophisticated models that can account for the intricate nature of sports injuries.

As the NFL continues to evolve with advances in technology and player tracking, there will be opportunities to refine injury prevention strategies further. Continuous investment in data analytics and research will enable the development of tailored interventions, improve player safety, and enrich the overall quality of the sport.

In conclusion, this paper not only corroborates some established understandings but also opens new avenues for inquiry into the environmental factors affecting NFL injuries. It prompts a re-evaluation of current practices and policies related to playing surfaces and game conditions, with the ultimate goal of reducing the incidence and severity of injuries for the welfare of athletes.


# References

@article{Mack2018,
  author = {Mack, Callie D. and Solomon, Gary and Covassin, Tracey and Theodore, Nicholas and Cárdenas, Javier and Sills, Allen},
  title = {Higher Rates of Lower Extremity Injury on Synthetic Turf Compared With Natural Turf Among National Football League Athletes: Epidemiological Confirmation of a Biomechanical Hypothesis},
  journal = {American Journal of Sports Medicine},
  year = {2018},
  volume = {46},
  number = {12},
  pages = {2781--2789},
  doi = {10.1177/0363546518808499}
}

@article{Haider2018,
  author = {Haider, Syed and Kaye-Kauderer, Halley P. and Maniya, Akbar Y. and Dai, Jennifer B. and Li, Adam Y. and Post, Alexander F. and Sobotka, Stanislaw S. and Adams, Ryan and Gometz, Alex and Lovell, Mark R. and Choudhri, Tanvir F.},
  title = {Does the Environment Influence the Frequency of Concussion Incidence in Professional Football?},
  journal = {Cureus},
  year = {2018},
  volume = {10},
  number = {11},
  pages = {e3627},
  doi = {10.7759/cureus.3627}
}

@article{SAGEArticle2018,
  author = {Author Names},
  title = {Title of the SAGE Journal Article},
  journal = {Journal Name},
  year = {2018},
  volume = {Volume Number},
  number = {Issue Number},
  pages = {Page Range},
  doi = {DOI if available}
}

